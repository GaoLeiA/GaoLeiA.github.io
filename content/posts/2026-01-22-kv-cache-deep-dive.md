---
layout: post
title: vLLM KV Cache æ·±åº¦è§£æ
category: ai
---

## ğŸ“‹ æ¦‚è¿°

KV Cache æ˜¯å¤§è¯­è¨€æ¨¡å‹æ¨ç†ä¸­æœ€é‡è¦çš„ä¼˜åŒ–æŠ€æœ¯ä¹‹ä¸€ã€‚æœ¬æ–‡æ¡£è¯¦ç»†ä»‹ç» vLLM ä¸­ KV Cache çš„å·¥ä½œåŸç†ã€å®ç°ç»†èŠ‚å’Œä¼˜åŒ–ç­–ç•¥ã€‚

---

## ğŸ§  ä»€ä¹ˆæ˜¯ KV Cacheï¼Ÿ

åœ¨ Transformer çš„è‡ªæ³¨æ„åŠ›æœºåˆ¶ä¸­ï¼Œæ¯ä¸ª token éƒ½éœ€è¦ä¸ä¹‹å‰æ‰€æœ‰ token è¿›è¡Œæ³¨æ„åŠ›è®¡ç®—ã€‚å¦‚æœæ¯æ¬¡ç”Ÿæˆæ–° token éƒ½é‡æ–°è®¡ç®—æ‰€æœ‰çš„ Key å’Œ Value å‘é‡ï¼Œè®¡ç®—é‡ä¼šéå¸¸å¤§ã€‚

**KV Cache çš„æ ¸å¿ƒæ€æƒ³**ï¼šç¼“å­˜å·²è®¡ç®—çš„ Key å’Œ Value å‘é‡ï¼Œé¿å…é‡å¤è®¡ç®—ã€‚

### æ•°å­¦åŸç†

```
Attention(Q, K, V) = softmax(QK^T / âˆšd_k) Ã— V

å…¶ä¸­ï¼š
- Q (Query): å½“å‰ token çš„æŸ¥è¯¢å‘é‡
- K (Key): æ‰€æœ‰ token çš„é”®å‘é‡
- V (Value): æ‰€æœ‰ token çš„å€¼å‘é‡
```

**æ²¡æœ‰ KV Cache**ï¼š
```
Step 1: è®¡ç®— token_0 çš„ K_0, V_0 â†’ ç”Ÿæˆ token_1
Step 2: è®¡ç®— token_0, token_1 çš„ K_0, K_1, V_0, V_1 â†’ ç”Ÿæˆ token_2
Step 3: è®¡ç®— token_0, token_1, token_2 çš„ K, V â†’ ç”Ÿæˆ token_3
...
è®¡ç®—å¤æ‚åº¦: O(nÂ²) éšåºåˆ—é•¿åº¦å¹³æ–¹å¢é•¿
```

**æœ‰ KV Cache**ï¼š
```
Step 1: è®¡ç®—å¹¶ç¼“å­˜ K_0, V_0 â†’ ç”Ÿæˆ token_1
Step 2: ä½¿ç”¨ç¼“å­˜çš„ K_0, V_0ï¼Œåªè®¡ç®—æ–°çš„ K_1, V_1 å¹¶ç¼“å­˜ â†’ ç”Ÿæˆ token_2
Step 3: ä½¿ç”¨ç¼“å­˜çš„ K_0, K_1, V_0, V_1ï¼Œåªè®¡ç®— K_2, V_2 å¹¶ç¼“å­˜ â†’ ç”Ÿæˆ token_3
...
è®¡ç®—å¤æ‚åº¦: O(n) çº¿æ€§å¢é•¿
```

---

## ğŸ¯ ä¼ ç»Ÿ KV Cache çš„é—®é¢˜

### å†…å­˜ç¢ç‰‡åŒ–

ä¼ ç»Ÿå®ç°ä¸ºæ¯ä¸ªè¯·æ±‚é¢„åˆ†é…å›ºå®šå¤§å°çš„è¿ç»­å†…å­˜ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Request A: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ____________]           â”‚ â† é¢„åˆ†é… max_seq_len
â”‚            å®é™…ä½¿ç”¨      é¢„ç•™ä½†æœªä½¿ç”¨            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Request B: [â–ˆâ–ˆâ–ˆâ–ˆ_______________]                â”‚ â† çŸ­è¯·æ±‚æµªè´¹æ›´å¤š
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Request C: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ]   â”‚ â† é•¿è¯·æ±‚å¯èƒ½è¶…å‡º
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**é—®é¢˜**ï¼š
1. **å†…å­˜æµªè´¹**ï¼šé¢„åˆ†é…ä½†æœªä½¿ç”¨çš„å†…å­˜é«˜è¾¾ 60-80%
2. **æ‰¹å¤§å°å—é™**ï¼šå› ç¢ç‰‡åŒ–æ— æ³•å……åˆ†åˆ©ç”¨ GPU å†…å­˜
3. **ä¸çµæ´»**ï¼šæ— æ³•é€‚åº”å˜é•¿åºåˆ—

---

## ğŸš€ vLLM çš„ PagedAttention æ–¹æ¡ˆ

vLLM æå‡ºäº† **PagedAttention**ï¼Œå€Ÿé‰´æ“ä½œç³»ç»Ÿè™šæ‹Ÿå†…å­˜çš„åˆ†é¡µæœºåˆ¶ï¼Œå°† KV Cache åˆ‡åˆ†ä¸ºå›ºå®šå¤§å°çš„å—ï¼ˆblockï¼‰è¿›è¡Œç®¡ç†ã€‚

### æ ¸å¿ƒè®¾è®¡

![KV Cache æ¶æ„](./images/vllm_kv_cache.png)

**å…³é”®æ¦‚å¿µ**ï¼š

| æ¦‚å¿µ | è¯´æ˜ |
|------|------|
| **Block** | å›ºå®šå¤§å°çš„ KV å­˜å‚¨å•å…ƒï¼Œé€šå¸¸ 16 tokens |
| **Block Size** | æ¯ä¸ªå—å­˜å‚¨çš„ token æ•°é‡ |
| **Block Table** | é€»è¾‘å—åˆ°ç‰©ç†å—çš„æ˜ å°„è¡¨ |
| **Block Pool** | ç®¡ç†æ‰€æœ‰å¯ç”¨å—çš„æ±  |

### å—ç»“æ„

```python
# å•ä¸ª KV Cache å—çš„ç»“æ„
Block {
    block_id: int           # ç‰©ç†å— ID
    num_tokens: int         # å·²å¡«å……çš„ token æ•° (0 ~ block_size)
    
    # æ¯å±‚æ¯å¤´çš„ KV å‘é‡
    k_cache: [block_size, num_heads, head_size]  # Key ç¼“å­˜
    v_cache: [block_size, num_heads, head_size]  # Value ç¼“å­˜
    
    # ç”¨äºå‰ç¼€ç¼“å­˜çš„å“ˆå¸Œå€¼
    block_hash: Optional[int]
}
```

### éè¿ç»­å†…å­˜åˆ†é…

```
ä¼ ç»Ÿè¿ç»­åˆ†é…ï¼š
Request A: [Block 0][Block 1][Block 2][Block 3] â† å¿…é¡»è¿ç»­

PagedAttention éè¿ç»­åˆ†é…ï¼š
Request A: [Block 0] â†’ [Block 5] â†’ [Block 2] â†’ [Block 8]
                  â†“          â†“          â†“          â†“
           ç‰©ç†ä½ç½®ä¸è¿ç»­ï¼Œé€šè¿‡ Block Table æ˜ å°„
```

---

## ğŸ“Š KV Cache æ¼”å˜è¿‡ç¨‹

### æ¨ç†è¿‡ç¨‹ä¸­çš„ KV Cache å˜åŒ–

ä¸‹å›¾å±•ç¤ºäº†å•ä¸ªè¯·æ±‚ä» Prefill åˆ° Decode é˜¶æ®µ KV Cache çš„å˜åŒ–ï¼š

![KV Cache Evolution](./images/kv_cache_evolution.png)

#### Phase 1: Prefillï¼ˆé¢„å¡«å……é˜¶æ®µï¼‰

```
è¾“å…¥ Prompt: "Hello, how are you?" (5 tokens)

1. ä¸€æ¬¡æ€§è®¡ç®—æ‰€æœ‰ token çš„ K, V
2. åˆ†é…è¶³å¤Ÿçš„å—å­˜å‚¨è¿™äº› KV
3. å—çŠ¶æ€: [B0: full][B1: partial]

GPU è®¡ç®—: å¹¶è¡Œå¤„ç†æ‰€æœ‰ 5 ä¸ª token
å†…å­˜æ“ä½œ: æ‰¹é‡å†™å…¥ KV Cache
```

#### Phase 2: Decodeï¼ˆè§£ç é˜¶æ®µï¼‰

```
ç”Ÿæˆç¬¬ 1 ä¸ª token: "I"
â”œâ”€ Query: åªæœ‰æ–° token
â”œâ”€ Key/Value: æ–° token + ç¼“å­˜çš„æ‰€æœ‰ KV
â”œâ”€ å†™å…¥æ–°çš„ K, V åˆ°å½“å‰å— (B1)
â””â”€ å¦‚æœå—æ»¡ï¼Œåˆ†é…æ–°å—

ç”Ÿæˆç¬¬ 2 ä¸ª token: "am"
â”œâ”€ åŒä¸Šï¼Œç´¯ç§¯ KV Cache
â””â”€ ...

ç”Ÿæˆç¬¬ N ä¸ª token: 
â”œâ”€ KV Cache æŒç»­å¢é•¿
â””â”€ åŠ¨æ€åˆ†é…æ–°å—
```

### å¤šè¯·æ±‚æ‰¹å¤„ç†åœºæ™¯

ä¸‹å›¾å±•ç¤ºäº†å¤šä¸ªå¹¶å‘è¯·æ±‚åŒæ—¶è¿è¡Œæ—¶ KV Cache çš„åŠ¨æ€å˜åŒ–ï¼š

![KV Cache Batching](./images/kv_cache_batching.png)

#### Timeline è¯¦è§£

| æ—¶é—´ | äº‹ä»¶ | Block Pool çŠ¶æ€ | GPU å†…å­˜ä½¿ç”¨ |
|------|------|-----------------|--------------|
| T=0 | åˆå§‹çŠ¶æ€ | æ‰€æœ‰å—ç©ºé—² | 0% |
| T=1 | Request A Prefill | B0, B1 åˆ†é…ç»™ A | 20% |
| T=2 | Request B åŠ å…¥ | B3-B5 åˆ†é…ç»™ Bï¼ŒB2 åˆ†é…ç»™ A | 60% |
| T=3 | Request C åŠ å…¥ | B7-B8 åˆ†é…ç»™ Cï¼ŒB6 åˆ†é…ç»™ B | 90% |
| T=4 | Request A å®Œæˆ | B0-B2 é‡Šæ”¾å›æ±  | 70% |
| T=5 | Request D å¤ç”¨ | B0, B1 è¢« D å¤ç”¨ | 80% |

**å…³é”®æ´å¯Ÿ**ï¼š
- å—åœ¨è¯·æ±‚å®Œæˆå**ç«‹å³é‡Šæ”¾**
- æ–°è¯·æ±‚å¯ä»¥**å¤ç”¨å·²é‡Šæ”¾çš„å—**
- **æ— éœ€é¢„åˆ†é…**å›ºå®šå¤§å°å†…å­˜
- GPU åˆ©ç”¨ç‡å¯è¾¾ **90%+**

---

## ğŸ”§ æ ¸å¿ƒç»„ä»¶è¯¦è§£

### 1. BlockPoolï¼ˆå—æ± ï¼‰

```python
class BlockPool:
    """ç®¡ç†æ‰€æœ‰ KV Cache å—çš„æ± """
    
    def __init__(self, num_blocks: int, block_size: int):
        self.free_blocks: List[int] = list(range(num_blocks))
        self.allocated_blocks: Dict[str, List[int]] = {}
    
    def allocate(self, request_id: str) -> int:
        """ä»æ± ä¸­åˆ†é…ä¸€ä¸ªå—"""
        if not self.free_blocks:
            raise OutOfMemoryError("No free blocks available")
        block_id = self.free_blocks.pop()
        self.allocated_blocks.setdefault(request_id, []).append(block_id)
        return block_id
    
    def free(self, request_id: str):
        """é‡Šæ”¾è¯·æ±‚çš„æ‰€æœ‰å—"""
        blocks = self.allocated_blocks.pop(request_id, [])
        self.free_blocks.extend(blocks)
```

### 2. KVCacheManagerï¼ˆç¼“å­˜ç®¡ç†å™¨ï¼‰

```python
class KVCacheManager:
    """KV Cache çš„é«˜çº§ç®¡ç†æ¥å£"""
    
    def get_computed_blocks(self, request: Request) -> Tuple[List[Block], int]:
        """è·å–è¯·æ±‚çš„å·²è®¡ç®—å—ï¼ˆç”¨äºå‰ç¼€ç¼“å­˜ï¼‰"""
        # æ£€æŸ¥æ˜¯å¦æœ‰å¯å¤ç”¨çš„å‰ç¼€
        cached_blocks = self.prefix_cache.lookup(request.prompt_hash)
        return cached_blocks, len(cached_blocks) * self.block_size
    
    def allocate_slots(self, request: Request, num_tokens: int) -> List[int]:
        """ä¸ºæ–° token åˆ†é… KV æ§½ä½"""
        required_blocks = ceil(num_tokens / self.block_size)
        allocated = []
        for _ in range(required_blocks):
            block = self.block_pool.allocate(request.request_id)
            allocated.append(block)
        return allocated
    
    def free(self, request: Request):
        """é‡Šæ”¾è¯·æ±‚çš„æ‰€æœ‰ KV Cache"""
        self.block_pool.free(request.request_id)
```

### 3. Block Tableï¼ˆå—è¡¨ï¼‰

```python
# é€»è¾‘å—åˆ°ç‰©ç†å—çš„æ˜ å°„
class BlockTable:
    """
    Request çš„å—æ˜ å°„è¡¨
    
    Logical Index:  [0,  1,  2,  3,  4]
                     â†“   â†“   â†“   â†“   â†“
    Physical Block: [B0, B5, B2, B8, B3]
    """
    
    def __init__(self):
        self.mapping: List[int] = []  # logical_idx -> physical_block_id
    
    def append(self, physical_block_id: int):
        self.mapping.append(physical_block_id)
    
    def get_physical_blocks(self) -> List[int]:
        return self.mapping
```

---

## ğŸŒ³ å‰ç¼€ç¼“å­˜ (Prefix Caching)

### åŸç†

å½“å¤šä¸ªè¯·æ±‚å…±äº«ç›¸åŒçš„å‰ç¼€ï¼ˆå¦‚ç³»ç»Ÿæç¤ºè¯ï¼‰æ—¶ï¼Œå¯ä»¥å¤ç”¨å·²è®¡ç®—çš„ KV Cacheã€‚

```
Request 1: "System: You are a helpful assistant. User: Hi"
Request 2: "System: You are a helpful assistant. User: Hello"
Request 3: "System: You are a helpful assistant. User: Help me"
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€å…±åŒå‰ç¼€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â””â”€ä¸åŒéƒ¨åˆ†â”€â”˜
```

### å®ç°

```python
# å‰ç¼€ç¼“å­˜ä½¿ç”¨æ ‘çŠ¶ç»“æ„
class PrefixCache:
    """
    æ ‘çŠ¶ç»“æ„å­˜å‚¨å‰ç¼€
    
           [Root]
              â”‚
    [System: You are helpful]  â† å…±äº«å— (Block 0-3)
         /        |        \
    [User: Hi] [User: Hello] [User: Help]
    (Block 4)   (Block 5)    (Block 6)
    """
    
    def lookup(self, token_ids: List[int]) -> List[Block]:
        """æŸ¥æ‰¾å¯å¤ç”¨çš„å‰ç¼€å—"""
        hash_key = self.compute_hash(token_ids)
        return self.cache.get(hash_key, [])
    
    def insert(self, token_ids: List[int], blocks: List[Block]):
        """æ’å…¥æ–°çš„å‰ç¼€åˆ°ç¼“å­˜"""
        hash_key = self.compute_hash(token_ids)
        self.cache[hash_key] = blocks
```

### èŠ‚çœæ•ˆæœ

```
ä¸ä½¿ç”¨å‰ç¼€ç¼“å­˜:
- Request 1: 5 blocks
- Request 2: 5 blocks  
- Request 3: 5 blocks
- æ€»è®¡: 15 blocks

ä½¿ç”¨å‰ç¼€ç¼“å­˜:
- å…±äº«å‰ç¼€: 4 blocks (åªè®¡ç®—ä¸€æ¬¡)
- Request 1 åç¼€: 1 block
- Request 2 åç¼€: 1 block
- Request 3 åç¼€: 1 block
- æ€»è®¡: 7 blocks (èŠ‚çœ 53%!)
```

---

## ğŸ’¾ KV Offloadï¼ˆç¼“å­˜å¸è½½ï¼‰

å¯¹äºè¶…é•¿ä¸Šä¸‹æ–‡ï¼ŒGPU å†…å­˜å¯èƒ½ä¸è¶³ã€‚vLLM æ”¯æŒå°†éƒ¨åˆ† KV Cache å¸è½½åˆ° CPU æˆ–ç£ç›˜ã€‚

### åˆ†å±‚æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Hot (GPU Memory)              â”‚ â† æœ€è¿‘ä½¿ç”¨ï¼Œè®¿é—®æœ€å¿«
â”‚  â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚ B0  â”‚ â”‚ B1  â”‚ â”‚ B2  â”‚ â”‚ B3  â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†• LRU/ARC eviction
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Warm (CPU Memory)             â”‚ â† è¾ƒå°‘ä½¿ç”¨ï¼Œè®¿é—®è¾ƒæ…¢
â”‚  â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚ B4  â”‚ â”‚ B5  â”‚ â”‚ B6  â”‚ â”‚ B7  â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†• eviction
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Cold (Disk/SSD)               â”‚ â† å¾ˆå°‘ä½¿ç”¨ï¼Œè®¿é—®æœ€æ…¢
â”‚  â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚ B8  â”‚ â”‚ B9  â”‚ â”‚ B10 â”‚ â”‚ ... â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### é©±é€ç­–ç•¥

| ç­–ç•¥ | è¯´æ˜ |
|------|------|
| **LRU** | Least Recently Usedï¼Œæœ€è¿‘æœ€å°‘ä½¿ç”¨ |
| **ARC** | Adaptive Replacement Cacheï¼Œè‡ªé€‚åº”æ›¿æ¢ |

---

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–æŠ€æœ¯

### 1. CUDA Graphs

å‡å°‘ CPU-GPU é€šä¿¡å¼€é”€ï¼š

```python
# é¦–æ¬¡è¿è¡Œï¼šæ•è·è®¡ç®—å›¾
with torch.cuda.graph(graph):
    output = model(input)

# åç»­è¿è¡Œï¼šé‡æ”¾è®¡ç®—å›¾
graph.replay()  # æä½çš„ CPU å¼€é”€
```

### 2. Slot Mapping ä¼˜åŒ–

```python
# å°†é€»è¾‘ä½ç½®æ˜ å°„åˆ°ç‰©ç†ä½ç½®
slot_mapping = torch.tensor([
    block_table[logical_idx] * block_size + offset
    for logical_idx, offset in token_positions
])

# ä½¿ç”¨ç´¢å¼•ç›´æ¥å†™å…¥ KV Cache
kv_cache[slot_mapping] = new_kv
```

### 3. Flash Attention é›†æˆ

```python
# Flash Attention æ”¯æŒåˆ†é¡µ KV Cache
flash_attn_with_kvcache(
    q=query,                    # [batch, 1, heads, head_dim]
    k_cache=k_cache,            # [num_blocks, block_size, heads, head_dim]
    v_cache=v_cache,            # [num_blocks, block_size, heads, head_dim]
    block_table=block_table,    # [batch, max_blocks]
    cache_seqlens=seq_lens,     # [batch]
)
```

---

## ğŸ“Š å†…å­˜è®¡ç®—

### KV Cache å¤§å°å…¬å¼

```
å•å±‚ KV Cache å¤§å° = 2 Ã— num_heads Ã— head_size Ã— seq_len Ã— dtype_size

æ€» KV Cache å¤§å° = num_layers Ã— å•å±‚å¤§å°

ç¤ºä¾‹ (Llama-2-7B):
- num_layers = 32
- num_heads = 32  
- head_size = 128
- seq_len = 4096
- dtype = float16 (2 bytes)

å•å±‚ = 2 Ã— 32 Ã— 128 Ã— 4096 Ã— 2 = 64 MB
æ€»è®¡ = 32 Ã— 64 MB = 2 GB per request!
```

### å—æ•°é‡è®¡ç®—

```
æ‰€éœ€å—æ•° = ceil(seq_len / block_size)

ç¤ºä¾‹:
- seq_len = 4096
- block_size = 16
- æ‰€éœ€å—æ•° = ceil(4096 / 16) = 256 blocks
```

---

## ğŸ”— ç›¸å…³ä»£ç ä½ç½®

| æ¨¡å— | æ–‡ä»¶è·¯å¾„ | è¯´æ˜ |
|------|----------|------|
| KV Cache ç®¡ç†å™¨ | `vllm/v1/core/kv_cache_manager.py` | é«˜çº§ç®¡ç†æ¥å£ |
| å—æ±  | `vllm/v1/core/block_pool.py` | å—åˆ†é…/é‡Šæ”¾ |
| KV Cache å·¥å…· | `vllm/v1/core/kv_cache_utils.py` | è¾…åŠ©å‡½æ•° (66KB) |
| å—è¡¨ | `vllm/v1/worker/block_table.py` | å—æ˜ å°„è¡¨ |
| Attention åç«¯ | `vllm/v1/attention/backends/` | å„ç§æ³¨æ„åŠ›å®ç° |
| KV Offload | `vllm/v1/kv_offload/` | ç¼“å­˜å¸è½½ |

---

## ğŸ“š å‚è€ƒèµ„æ–™

- [vLLM: Easy, Fast, and Cheap LLM Serving with PagedAttention](https://arxiv.org/abs/2309.06180)
- [FlashAttention-2: Faster Attention with Better Parallelism](https://arxiv.org/abs/2307.08691)
- [vLLM å®˜æ–¹æ–‡æ¡£](https://docs.vllm.ai/)

---

## ğŸ¯ æ€»ç»“

vLLM çš„ KV Cache ç®¡ç†é€šè¿‡ä»¥ä¸‹åˆ›æ–°å®ç°äº†é«˜æ•ˆå†…å­˜åˆ©ç”¨ï¼š

| æŠ€æœ¯ | æ•ˆæœ |
|------|------|
| **PagedAttention** | æ¶ˆé™¤å†…å­˜ç¢ç‰‡ï¼Œæé«˜åˆ©ç”¨ç‡ 50%+ |
| **éè¿ç»­åˆ†é…** | çµæ´»çš„å†…å­˜ç®¡ç† |
| **å‰ç¼€ç¼“å­˜** | å…±äº«è®¡ç®—ï¼Œå‡å°‘é‡å¤ |
| **åŠ¨æ€åˆ†é…** | æŒ‰éœ€åˆ†é…ï¼Œæ— æµªè´¹ |
| **å³æ—¶é‡Šæ”¾** | å—å¯ç«‹å³å¤ç”¨ |
| **KV Offload** | æ”¯æŒè¶…é•¿ä¸Šä¸‹æ–‡ |

è¿™äº›æŠ€æœ¯å…±åŒä½¿ vLLM æˆä¸ºç›®å‰æœ€é«˜æ•ˆçš„å¼€æº LLM æ¨ç†å¼•æ“ä¹‹ä¸€ã€‚
