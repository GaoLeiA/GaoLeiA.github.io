---
layout: post
title: PagedAttention ä¸ Continuous Batching æ·±åº¦è§£æ
category: ai
---

## ğŸ“‹ æ¦‚è¿°

**PagedAttention** å’Œ **Continuous Batching** æ˜¯ vLLM å®ç°é«˜æ€§èƒ½ LLM æ¨ç†çš„ä¸¤å¤§æ ¸å¿ƒæŠ€æœ¯ã€‚å®ƒä»¬å…±åŒè§£å†³äº†ä¼ ç»Ÿæ¨ç†ç³»ç»Ÿä¸­çš„å†…å­˜æ•ˆç‡å’Œååé‡é—®é¢˜ã€‚

| æŠ€æœ¯ | è§£å†³çš„é—®é¢˜ | æ•ˆæœ |
|------|-----------|------|
| **PagedAttention** | å†…å­˜ç¢ç‰‡åŒ–ã€å†…å­˜æµªè´¹ | å†…å­˜åˆ©ç”¨ç‡ä» 35% æå‡åˆ° 95%+ |
| **Continuous Batching** | GPU åˆ©ç”¨ç‡ä½ã€å»¶è¿Ÿé«˜ | ååé‡æå‡ 3-5 å€ |

---

## ğŸŸ£ Part 1: PagedAttention

### 1.1 ä¼ ç»Ÿæ–¹æ¡ˆçš„é—®é¢˜

ä¼ ç»Ÿ LLM æ¨ç†ç³»ç»Ÿä¸ºæ¯ä¸ªè¯·æ±‚é¢„åˆ†é…å›ºå®šå¤§å°çš„è¿ç»­å†…å­˜ï¼š

```
ä¼ ç»Ÿå†…å­˜åˆ†é…ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Request A: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ____________________________]        â”‚
â”‚            å®é™…ä½¿ç”¨ 40%    é¢„ç•™ä½†æœªä½¿ç”¨ 60%                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Request B: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ__________] â† çŸ­è¯·æ±‚æµªè´¹æ›´ä¸¥é‡              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Request C: æ— æ³•åˆ†é…ï¼å†…å­˜ç¢ç‰‡åŒ–å¯¼è‡´ç©ºé—´ä¸è¶³                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**æ ¸å¿ƒé—®é¢˜**ï¼š

| é—®é¢˜ | è¯´æ˜ |
|------|------|
| ğŸ”´ é¢„åˆ†é…æµªè´¹ | æ¯ä¸ªè¯·æ±‚é¢„ç•™ `max_seq_len` å¤§å°çš„å†…å­˜ |
| ğŸ”´ å†…å­˜ç¢ç‰‡åŒ– | ä¸è¿ç»­çš„å°ç©ºé—´æ— æ³•åˆ©ç”¨ |
| ğŸ”´ æ‰¹å¤§å°å—é™ | å†…å­˜æµªè´¹å¯¼è‡´å¹¶å‘è¯·æ±‚æ•°å‡å°‘ |
| ğŸ”´ ä¸å¯é¢„æµ‹ | æ— æ³•é¢„çŸ¥æ¯ä¸ªè¯·æ±‚çš„å®é™…é•¿åº¦ |

### 1.2 PagedAttention è§£å†³æ–¹æ¡ˆ

PagedAttention å€Ÿé‰´äº†æ“ä½œç³»ç»Ÿçš„**è™šæ‹Ÿå†…å­˜åˆ†é¡µ**æœºåˆ¶ï¼š

![PagedAttention è¯¦è§£](./images/paged_attention_detail.png)

**æ ¸å¿ƒæ€æƒ³**ï¼šå°† KV Cache åˆ‡åˆ†ä¸ºå›ºå®šå¤§å°çš„**å—ï¼ˆBlockï¼‰**ï¼ŒæŒ‰éœ€åŠ¨æ€åˆ†é…ã€‚

```
æ“ä½œç³»ç»Ÿè™šæ‹Ÿå†…å­˜:
[è™šæ‹Ÿåœ°å€ç©ºé—´] â†’ [é¡µè¡¨] â†’ [ç‰©ç†å†…å­˜é¡µ]

PagedAttention:
[é€»è¾‘å—ç´¢å¼•] â†’ [å—è¡¨ Block Table] â†’ [ç‰©ç†å—]
```

### 1.3 å—ï¼ˆBlockï¼‰ç»“æ„

æ¯ä¸ªç‰©ç†å—å­˜å‚¨å›ºå®šæ•°é‡çš„ token çš„ KV å‘é‡ï¼š

```python
class PhysicalBlock:
    """ç‰©ç†å—ç»“æ„"""
    
    block_id: int           # å”¯ä¸€æ ‡è¯†ç¬¦
    block_size: int = 16    # æ¯å—å­˜å‚¨çš„ token æ•°
    
    # KV Cache å­˜å‚¨
    k_cache: Tensor  # shape: [block_size, num_heads, head_dim]
    v_cache: Tensor  # shape: [block_size, num_heads, head_dim]
    
    # å…ƒä¿¡æ¯
    num_tokens: int  # å½“å‰å·²å¡«å……çš„ token æ•° (0 ~ block_size)
    ref_count: int   # å¼•ç”¨è®¡æ•° (ç”¨äºå‰ç¼€ç¼“å­˜å…±äº«)
```

**å†…å­˜å¸ƒå±€**ï¼š

```
ç‰©ç†å— 42 (block_size=16):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ K Cache:                                        â”‚
â”‚ â”Œâ”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬...â”¬â”€â”€â”€â”€â”       â”‚
â”‚ â”‚ Kâ‚€ â”‚ Kâ‚ â”‚ Kâ‚‚ â”‚ Kâ‚ƒ â”‚ Kâ‚„ â”‚ Kâ‚… â”‚   â”‚Kâ‚â‚…â”‚       â”‚
â”‚ â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”´â”€â”€â”€â”€â”´â”€â”€â”€â”€â”´â”€â”€â”€â”€â”´â”€â”€â”€â”€â”´...â”´â”€â”€â”€â”€â”˜       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ V Cache:                                        â”‚
â”‚ â”Œâ”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬...â”¬â”€â”€â”€â”€â”       â”‚
â”‚ â”‚ Vâ‚€ â”‚ Vâ‚ â”‚ Vâ‚‚ â”‚ Vâ‚ƒ â”‚ Vâ‚„ â”‚ Vâ‚… â”‚   â”‚Vâ‚â‚…â”‚       â”‚
â”‚ â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”´â”€â”€â”€â”€â”´â”€â”€â”€â”€â”´â”€â”€â”€â”€â”´â”€â”€â”€â”€â”´...â”´â”€â”€â”€â”€â”˜       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
æ¯ä¸ª K/V å‘é‡å¤§å°: num_heads Ã— head_dim
```

### 1.4 å—è¡¨ï¼ˆBlock Tableï¼‰æ˜ å°„

æ¯ä¸ªè¯·æ±‚ç»´æŠ¤ä¸€ä¸ªå—è¡¨ï¼Œè®°å½•é€»è¾‘å—åˆ°ç‰©ç†å—çš„æ˜ å°„ï¼š

```python
class BlockTable:
    """
    é€»è¾‘å— â†’ ç‰©ç†å—çš„æ˜ å°„
    
    Request A çš„å—è¡¨:
    é€»è¾‘ç´¢å¼•:  [0] â†’ [1] â†’ [2] â†’ [3]
                â†“     â†“     â†“     â†“
    ç‰©ç†å— ID: [7]   [2]   [9]   [0]
    
    ç‰©ç†å—å¯ä»¥æ˜¯ä¸è¿ç»­çš„ï¼
    """
    
    def __init__(self):
        self.mapping: List[int] = []
    
    def get_physical_block(self, logical_idx: int) -> int:
        return self.mapping[logical_idx]
    
    def append_block(self, physical_block_id: int):
        self.mapping.append(physical_block_id)
```

### 1.5 Slot Mappingï¼ˆæ§½ä½æ˜ å°„ï¼‰

Token ä½ç½®åˆ°ç‰©ç†å†…å­˜ä½ç½®çš„è®¡ç®—ï¼š

```python
def compute_slot_mapping(token_position: int, 
                         block_table: List[int],
                         block_size: int = 16) -> int:
    """
    è®¡ç®— token åœ¨ç‰©ç†å†…å­˜ä¸­çš„ä½ç½®
    
    ç¤ºä¾‹: token_position = 35, block_size = 16
    """
    # 1. è®¡ç®—é€»è¾‘å—ç´¢å¼•
    logical_block_idx = token_position // block_size  # 35 // 16 = 2
    
    # 2. è®¡ç®—å—å†…åç§»
    offset_in_block = token_position % block_size     # 35 % 16 = 3
    
    # 3. æŸ¥è¯¢ç‰©ç†å— ID
    physical_block_id = block_table[logical_block_idx]  # block_table[2] = 9
    
    # 4. è®¡ç®—ç‰©ç†æ§½ä½
    physical_slot = physical_block_id * block_size + offset_in_block
    # physical_slot = 9 * 16 + 3 = 147
    
    return physical_slot  # 147
```

### 1.6 åˆ†é¡µå¼æ³¨æ„åŠ›è®¡ç®—

ä½¿ç”¨åˆ†é¡µ KV Cache çš„æ³¨æ„åŠ›è®¡ç®—æ­¥éª¤ï¼š

```python
def paged_attention(query: Tensor,           # [1, num_heads, head_dim]
                    kv_cache: Tensor,         # [num_blocks, block_size, num_heads, head_dim]
                    block_table: List[int],   # å—æ˜ å°„è¡¨
                    seq_len: int) -> Tensor:
    """
    åˆ†é¡µå¼æ³¨æ„åŠ›è®¡ç®—
    """
    # Step 1: ä»éè¿ç»­çš„ç‰©ç†å—ä¸­æ”¶é›† K å‘é‡
    k_gathered = []
    for logical_idx, physical_block in enumerate(block_table):
        k_gathered.append(kv_cache[physical_block, :, 0, :])  # å– K
    k_all = torch.cat(k_gathered, dim=0)[:seq_len]  # [seq_len, num_heads, head_dim]
    
    # Step 2: è®¡ç®—æ³¨æ„åŠ›åˆ†æ•°
    # scores = Q Ã— K^T / âˆšd
    scores = torch.matmul(query, k_all.transpose(-1, -2)) / math.sqrt(head_dim)
    
    # Step 3: Softmax
    attention_weights = torch.softmax(scores, dim=-1)
    
    # Step 4: ä»ç‰©ç†å—ä¸­æ”¶é›† V å‘é‡
    v_gathered = []
    for physical_block in block_table:
        v_gathered.append(kv_cache[physical_block, :, 1, :])  # å– V
    v_all = torch.cat(v_gathered, dim=0)[:seq_len]
    
    # Step 5: åŠ æƒæ±‚å’Œ
    output = torch.matmul(attention_weights, v_all)
    
    return output
```

### 1.7 å†…å­˜æ•ˆç‡å¯¹æ¯”

![KV Cache æ¶æ„å¯¹æ¯”](./images/vllm_kv_cache.png)

| æŒ‡æ ‡ | ä¼ ç»Ÿæ–¹æ¡ˆ | PagedAttention |
|------|----------|----------------|
| å†…å­˜åˆ©ç”¨ç‡ | 30-40% | 90-95% |
| å†…å­˜ç¢ç‰‡ | ä¸¥é‡ | å‡ ä¹æ²¡æœ‰ |
| æœ€å¤§æ‰¹å¤§å° | å—é™ | æå‡ 2-4 å€ |
| é•¿çŸ­è¯·æ±‚æ··åˆ | æ•ˆç‡ä½ | é«˜æ•ˆ |

---

## ğŸŸ¢ Part 2: Continuous Batching

### 2.1 é™æ€æ‰¹å¤„ç†çš„é—®é¢˜

ä¼ ç»Ÿé™æ€æ‰¹å¤„ç†éœ€è¦ç­‰å¾…æ•´ä¸ªæ‰¹æ¬¡å®Œæˆï¼š

```
é™æ€æ‰¹å¤„ç† (Static Batching):
                    æ—¶é—´ â†’
Batch 1: â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
         â”‚ Request A: ç”Ÿæˆ 100 tokens                 â”‚ â† æœ€é•¿è¯·æ±‚
         â”‚ Request B: ç”Ÿæˆ 30 tokens â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–’â–’â–’â–’â–’â–’â–’â–’â–’â”‚ â† ç­‰å¾… A
         â”‚ Request C: ç”Ÿæˆ 50 tokens â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–’â–’â”‚ â† ç­‰å¾… A
         â””â”€â”€â”€ æ•´ä¸ª Batch ç­‰å¾…æœ€é•¿è¯·æ±‚å®Œæˆ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         
              â†“ Batch 1 å®Œæˆåæ‰å¼€å§‹ Batch 2
              
Batch 2: â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
         â”‚ Request D, E, F...                 â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**é—®é¢˜**ï¼š
- âŒ çŸ­è¯·æ±‚è¢«é•¿è¯·æ±‚é˜»å¡
- âŒ GPU åœ¨ç­‰å¾…æ—¶ç©ºé—²
- âŒ å¹³å‡å»¶è¿Ÿé«˜
- âŒ ååé‡ä½

### 2.2 Continuous Batching è§£å†³æ–¹æ¡ˆ

Continuous Batching å…è®¸è¯·æ±‚åœ¨**è¿­ä»£çº§åˆ«**åŠ¨æ€åŠ å…¥å’Œç¦»å¼€ï¼š

![Continuous Batching è¯¦è§£](./images/continuous_batching_detail.png)

```
è¿ç»­æ‰¹å¤„ç† (Continuous Batching):
                    æ—¶é—´ â†’
Request A: â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
Request B: â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â†’ å®Œæˆï¼Œç«‹å³ç¦»å¼€
Request C: â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â†’ å®Œæˆ
Request D:           â”œâ† åŠ å…¥ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
Request E:                    â”œâ† åŠ å…¥ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
Request F:                              â”œâ† åŠ å…¥ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤

ç‰¹ç‚¹:
âœ… è¯·æ±‚éšæ—¶åŠ å…¥
âœ… è¯·æ±‚å®Œæˆåç«‹å³ç¦»å¼€
âœ… GPU å§‹ç»ˆæ»¡è½½
âœ… ä½å»¶è¿Ÿ + é«˜åå
```

### 2.3 è¿­ä»£çº§è°ƒåº¦

æ¯æ¬¡æ¨¡å‹å‰å‘ä¼ æ’­ï¼ˆiterationï¼‰éƒ½å¯ä»¥è°ƒæ•´æ‰¹æ¬¡ç»„æˆï¼š

```python
class Scheduler:
    """
    è¿­ä»£çº§è°ƒåº¦å™¨
    """
    
    def __init__(self):
        self.waiting_queue: Deque[Request] = deque()  # ç­‰å¾…é˜Ÿåˆ—
        self.running_queue: Dict[str, Request] = {}   # è¿è¡Œä¸­è¯·æ±‚
    
    def schedule(self) -> SchedulerOutput:
        """
        æ¯æ¬¡è¿­ä»£è°ƒç”¨ä¸€æ¬¡
        """
        # 1. å¤„ç†å·²å®Œæˆçš„è¯·æ±‚
        finished = []
        for req_id, req in self.running_queue.items():
            if req.is_finished():
                finished.append(req_id)
                self.kv_cache_manager.free(req)  # é‡Šæ”¾ KV Cache
        
        for req_id in finished:
            del self.running_queue[req_id]
        
        # 2. å°è¯•æ¥çº³æ–°è¯·æ±‚
        while self.waiting_queue and self.has_memory():
            new_req = self.waiting_queue.popleft()
            blocks = self.kv_cache_manager.allocate(new_req)
            self.running_queue[new_req.id] = new_req
        
        # 3. æ„å»ºæœ¬æ¬¡è¿­ä»£çš„æ‰¹æ¬¡
        batch = []
        for req in self.running_queue.values():
            if req.is_prefill:
                batch.append(ScheduledRequest(req, num_tokens=len(req.prompt)))
            else:
                batch.append(ScheduledRequest(req, num_tokens=1))
        
        return SchedulerOutput(scheduled_requests=batch)
```

### 2.4 Prefill vs Decode é˜¶æ®µ

LLM æ¨ç†æœ‰ä¸¤ä¸ªä¸åŒç‰¹æ€§çš„é˜¶æ®µï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Prefill é˜¶æ®µ                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ è¾“å…¥: "What is machine learning?" (5 tokens)                â”‚
â”‚                                                             â”‚
â”‚ å¤„ç†: å¹¶è¡Œè®¡ç®—æ‰€æœ‰ 5 ä¸ª token                                â”‚
â”‚       [T1, T2, T3, T4, T5] â”€â”€â†’ [Model] â”€â”€â†’ [K, V Cache]    â”‚
â”‚                                                             â”‚
â”‚ ç‰¹ç‚¹:                                                       â”‚
â”‚   â€¢ Compute-bound (è®¡ç®—å¯†é›†)                                 â”‚
â”‚   â€¢ é«˜ GPU åˆ©ç”¨ç‡                                            â”‚
â”‚   â€¢ ä¸€æ¬¡æ€§å¤„ç†å¤šä¸ª token                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Decode é˜¶æ®µ                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ç”Ÿæˆ: é€ä¸ªç”Ÿæˆ token (è‡ªå›å½’)                                 â”‚
â”‚                                                             â”‚
â”‚ Step 1: [KV Cache] + new_query â”€â”€â†’ token_6                 â”‚
â”‚ Step 2: [KV Cache + K6,V6] + query â”€â”€â†’ token_7             â”‚
â”‚ Step 3: [KV Cache + K6,V6,K7,V7] â”€â”€â†’ token_8               â”‚
â”‚ ...                                                         â”‚
â”‚                                                             â”‚
â”‚ ç‰¹ç‚¹:                                                       â”‚
â”‚   â€¢ Memory-bound (å†…å­˜å¯†é›†)                                  â”‚
â”‚   â€¢ æ¯æ­¥åªç”Ÿæˆ 1 ä¸ª token                                    â”‚
â”‚   â€¢ ä¸»è¦æ—¶é—´åœ¨è¯»å– KV Cache                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**æ··åˆæ‰¹å¤„ç†**ï¼šContinuous Batching å¯ä»¥åŒæ—¶å¤„ç† Prefill å’Œ Decodeï¼š

```
æ··åˆæ‰¹æ¬¡ç¤ºä¾‹:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Iteration 5:                                â”‚
â”‚   â€¢ Request A: decode (1 token)            â”‚
â”‚   â€¢ Request B: decode (1 token)            â”‚
â”‚   â€¢ Request C: prefill (50 tokens) â† NEW   â”‚
â”‚   â€¢ Request D: prefill (30 tokens) â† NEW   â”‚
â”‚                                             â”‚
â”‚ Total tokens: 82                            â”‚
â”‚ Batch size: 4 requests                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.5 Chunked Prefillï¼ˆåˆ†å—é¢„å¡«å……ï¼‰

å¯¹äºé•¿ Promptï¼Œåˆ†å—å¤„ç†é¿å…é˜»å¡å…¶ä»–è¯·æ±‚ï¼š

```
åŸå§‹ Prompt: 2048 tokens
            â†“ åˆ†å—
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Chunk 1: 512 tokens                                         â”‚
â”‚ Chunk 2: 512 tokens                                         â”‚
â”‚ Chunk 3: 512 tokens                                         â”‚
â”‚ Chunk 4: 512 tokens                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

äº¤é”™å¤„ç†:
â”‚Chunk 1â”‚Decode A,Bâ”‚Chunk 2â”‚Decode A,Bâ”‚Chunk 3â”‚Decode A,Bâ”‚Chunk 4â”‚
                                                              â†“
                                            é•¿ prompt ä¸é˜»å¡å…¶ä»–è¯·æ±‚
```

**é…ç½®å‚æ•°**ï¼š

```python
# vLLM é…ç½®
scheduler_config = SchedulerConfig(
    max_num_batched_tokens=2048,   # æ¯æ¬¡è¿­ä»£æœ€å¤§ token æ•°
    max_num_seqs=256,              # æœ€å¤§å¹¶å‘è¯·æ±‚æ•°
    max_model_len=32768,           # æœ€å¤§åºåˆ—é•¿åº¦
    enable_chunked_prefill=True,   # å¯ç”¨åˆ†å—é¢„å¡«å……
    max_prefill_tokens=512,        # æ¯å—æœ€å¤§ token æ•°
)
```

### 2.6 è°ƒåº¦å™¨è¾“å‡ºç»“æ„

```python
@dataclass
class SchedulerOutput:
    """è°ƒåº¦å™¨è¾“å‡º"""
    
    # æœ¬æ¬¡è¿­ä»£è¦å¤„ç†çš„è¯·æ±‚
    scheduled_requests: List[ScheduledRequest]
    
    # æ¯ä¸ªè¯·æ±‚çš„ä¿¡æ¯
    # ScheduledRequest:
    #   - request_id: str
    #   - num_tokens: int          # æœ¬æ¬¡å¤„ç†çš„ token æ•°
    #   - is_prefill: bool         # æ˜¯å¦æ˜¯ prefill é˜¶æ®µ
    #   - block_table: List[int]   # KV Cache å—è¡¨
    
    # å·²å®Œæˆçš„è¯·æ±‚ ID
    finished_request_ids: List[str]
    
    # è¢«æŠ¢å çš„è¯·æ±‚ (å†…å­˜ä¸è¶³æ—¶)
    preempted_request_ids: List[str]
    
    # ç»Ÿè®¡ä¿¡æ¯
    total_num_scheduled_tokens: int
    num_prefill_requests: int
    num_decode_requests: int
```

---

## ğŸ”µ Part 3: ä¸¤è€…å¦‚ä½•ååŒå·¥ä½œ

PagedAttention å’Œ Continuous Batching ç›¸äº’å¢å¼ºï¼Œå½¢æˆå®Œç¾ç»„åˆï¼š

![PagedAttention + Continuous Batching ååŒ](./images/paged_continuous_combined.png)

### 3.1 ååŒæ•ˆåº”

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ååŒæ•ˆåº”                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  PagedAttention                  Continuous Batching        â”‚
â”‚       â”‚                               â”‚                     â”‚
â”‚       â–¼                               â–¼                     â”‚
â”‚  æ¶ˆé™¤å†…å­˜ç¢ç‰‡  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’  æ›´å¤šè¯·æ±‚è¿›å…¥æ‰¹æ¬¡            â”‚
â”‚       â”‚                               â”‚                     â”‚
â”‚       â–¼                               â–¼                     â”‚
â”‚  æŒ‰éœ€åˆ†é…å†…å­˜  â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  è¯·æ±‚åŠ¨æ€åŠ å…¥/ç¦»å¼€           â”‚
â”‚       â”‚                               â”‚                     â”‚
â”‚       â–¼                               â–¼                     â”‚
â”‚  å³æ—¶é‡Šæ”¾å—    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’  æ–°è¯·æ±‚ç«‹å³å¤ç”¨              â”‚
â”‚       â”‚                               â”‚                     â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚                       â–¼                                     â”‚
â”‚              GPU åˆ©ç”¨ç‡æœ€å¤§åŒ–                                â”‚
â”‚              (å†…å­˜ 95% + è®¡ç®— 90%)                           â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.2 æ—¶é—´çº¿ç¤ºä¾‹

```
æ—¶é—´çº¿å±•ç¤ºä¸¤è€…ååŒ:

T=0: ç³»ç»Ÿå¯åŠ¨
     GPU Memory: [Free][Free][Free][Free][Free][Free][Free][Free]
     Batch: []

T=1: Request A åˆ°è¾¾ (Prefill 20 tokens)
     GPU Memory: [A][A][Free][Free][Free][Free][Free][Free]
                 â†‘ PagedAttention: åªåˆ†é…éœ€è¦çš„ 2 å—
     Batch: [A: prefill]
            â†‘ Continuous: ç«‹å³å¼€å§‹å¤„ç†

T=2: A åœ¨è§£ç ï¼ŒRequest B åˆ°è¾¾
     GPU Memory: [A][A][A][B][B][B][Free][Free]
                       â†‘    â†‘ B çš„å—å¯ä»¥ä¸è¿ç»­
     Batch: [A: decode, B: prefill]
            â†‘ Continuous: B ç«‹å³åŠ å…¥æ‰¹æ¬¡

T=3: A, B éƒ½åœ¨è§£ç ï¼ŒRequest C åˆ°è¾¾
     GPU Memory: [A][A][A][B][B][B][C][C]
     Batch: [A, B, C: all decode/prefill]
            â†‘ Continuous: 3 ä¸ªè¯·æ±‚å¹¶å‘

T=4: Request A å®Œæˆ
     GPU Memory: [â˜…][â˜…][â˜…][B][B][B][C][C]
                 â†‘ ç«‹å³é‡Šæ”¾  â†‘ ç»§ç»­ä½¿ç”¨
     Batch: [B, C]
            â†‘ A ç¦»å¼€ï¼Œè…¾å‡ºèµ„æº

T=5: Request D å¤ç”¨ A çš„å—
     GPU Memory: [D][D][Free][B][B][B][C][C]
                 â†‘ å¤ç”¨å—     â†‘ æœ‰ç©ºé—²å—
     Batch: [B, C, D]
            â†‘ D ç«‹å³åŠ å…¥
```

### 3.3 æ€§èƒ½å¯¹æ¯”

| æŒ‡æ ‡ | é™æ€æ‰¹å¤„ç† + è¿ç»­å†…å­˜ | Continuous + Paged |
|------|----------------------|-------------------|
| å†…å­˜åˆ©ç”¨ç‡ | 30-40% | **95%+** |
| GPU è®¡ç®—åˆ©ç”¨ç‡ | 40-50% | **90%+** |
| ååé‡ | 1x (åŸºå‡†) | **3-5x** |
| å¹³å‡å»¶è¿Ÿ | é«˜ | **ä½** |
| P99 å»¶è¿Ÿ | éå¸¸é«˜ | **å¯æ§** |
| æ‰¹å¤§å° | å›ºå®š | **åŠ¨æ€** |
| é•¿çŸ­è¯·æ±‚æ··åˆ | æ•ˆç‡ä½ | **é«˜æ•ˆ** |

---

## ğŸ“ Part 4: å®ç°ç»†èŠ‚

### 4.1 æ ¸å¿ƒä»£ç ä½ç½®

| æ¨¡å— | æ–‡ä»¶è·¯å¾„ | è¯´æ˜ |
|------|----------|------|
| **Scheduler** | `vllm/v1/core/sched/scheduler.py` | è°ƒåº¦å™¨æ ¸å¿ƒ (99KB) |
| **KVCacheManager** | `vllm/v1/core/kv_cache_manager.py` | KV ç¼“å­˜ç®¡ç† |
| **BlockPool** | `vllm/v1/core/block_pool.py` | å—æ± ç®¡ç† |
| **BlockTable** | `vllm/v1/worker/block_table.py` | å—è¡¨å®ç° |
| **GPUModelRunner** | `vllm/v1/worker/gpu_model_runner.py` | æ¨¡å‹æ‰§è¡Œ (6000+ è¡Œ) |

### 4.2 å…³é”®é…ç½®å‚æ•°

```python
from vllm import LLM, SamplingParams

llm = LLM(
    model="meta-llama/Llama-2-7b-hf",
    
    # PagedAttention ç›¸å…³
    block_size=16,              # æ¯å— token æ•°
    gpu_memory_utilization=0.9, # GPU å†…å­˜ä½¿ç”¨æ¯”ä¾‹
    
    # Continuous Batching ç›¸å…³
    max_num_seqs=256,           # æœ€å¤§å¹¶å‘è¯·æ±‚æ•°
    max_num_batched_tokens=8192, # æ¯æ¬¡è¿­ä»£æœ€å¤§ token æ•°
    
    # Chunked Prefill
    enable_chunked_prefill=True,
    max_num_partial_prefills=1,
)
```

### 4.3 ç›‘æ§æŒ‡æ ‡

```python
# å…³é”®ç›‘æ§æŒ‡æ ‡
metrics = {
    # PagedAttention ç›¸å…³
    "kv_cache_usage": 0.85,          # KV Cache ä½¿ç”¨ç‡
    "num_free_blocks": 1024,         # ç©ºé—²å—æ•°é‡
    "num_allocated_blocks": 5120,    # å·²åˆ†é…å—æ•°é‡
    
    # Continuous Batching ç›¸å…³
    "num_running_requests": 64,      # è¿è¡Œä¸­è¯·æ±‚æ•°
    "num_waiting_requests": 128,     # ç­‰å¾…ä¸­è¯·æ±‚æ•°
    "batch_size": 64,                # å½“å‰æ‰¹å¤§å°
    "tokens_per_second": 10000,      # ååé‡ (tokens/s)
    
    # å»¶è¿Ÿç›¸å…³
    "avg_prefill_latency_ms": 50,    # å¹³å‡ prefill å»¶è¿Ÿ
    "avg_decode_latency_ms": 10,     # å¹³å‡ decode å»¶è¿Ÿ
    "avg_e2e_latency_ms": 500,       # å¹³å‡ç«¯åˆ°ç«¯å»¶è¿Ÿ
}
```

---

## ğŸ“š å‚è€ƒèµ„æ–™

- [Efficient Memory Management for Large Language Model Serving with PagedAttention](https://arxiv.org/abs/2309.06180)
- [ORCA: A Distributed Serving System for Transformer-Based Generative Models](https://www.usenix.org/conference/osdi22/presentation/yu)
- [vLLM å®˜æ–¹æ–‡æ¡£](https://docs.vllm.ai/)

---

## ğŸ¯ æ€»ç»“

| æŠ€æœ¯ | æ ¸å¿ƒæ€æƒ³ | å…³é”®æ•ˆæœ |
|------|----------|----------|
| **PagedAttention** | å€Ÿé‰´ OS è™šæ‹Ÿå†…å­˜åˆ†é¡µ | æ¶ˆé™¤ç¢ç‰‡ï¼Œæå‡å†…å­˜åˆ©ç”¨ç‡ |
| **Continuous Batching** | è¿­ä»£çº§åŠ¨æ€è°ƒåº¦ | æœ€å¤§åŒ– GPU åˆ©ç”¨ç‡ |
| **ä¸¤è€…ç»“åˆ** | å†…å­˜ + è®¡ç®—åŒä¼˜åŒ– | 3-5x ååé‡æå‡ |

è¿™ä¸¤é¡¹æŠ€æœ¯çš„ç»“åˆä½¿ vLLM æˆä¸ºå½“å‰æœ€é«˜æ•ˆçš„å¼€æº LLM æ¨ç†å¼•æ“ã€‚
